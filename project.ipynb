{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import wave \n",
    "import xenocanto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = ['Emberiza citrinella','Cuculus canorus','Emberiza cirlus']\n",
    "dataset_dir = Path('dataset')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, cache and extract birds songs from xeno canto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not (dataset_dir/'testing_list.txt').exists(): # Assume dataset already downloaded/extracted if testing list is present\n",
    "    for bird in birds : \n",
    "        xenocanto.metadata([bird,\"type:song\",\"q:A\"])\n",
    "        xenocanto.metadata([bird,\"type:song\",\"q:B\"])\n",
    "        await xenocanto.download([bird,\"type:song\",\"q:A\"],2)\n",
    "        await xenocanto.download([bird,\"type:song\",\"q:B\"],2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after loading the data : in powershell in repository dataset/audio : \n",
    "```ps\n",
    " Get-ChildItem  . -Recurse -Filter *.mp3 | ForEach-Object {  $input = $_.Fullname $newname = $_.Fullname.replace(\".mp3\",\"\")+_03d.mp3; ffmpeg -i $input -f segment -segment_time 10 $newname; rm $input}\n",
    " Get-ChildItem  . -Recurse -Filter *.mp3 | ForEach-Object {  $input = $_.Fullname;$newname = $_.Fullname.replace(\".mp3\",\".wav\"); ffmpeg -i $input -ac 2 -ar 48000 $newname; rm $input}\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3575\n",
      "3575\n",
      "3575\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not (dataset_dir/'testing_list.txt').exists(): # Assume dataset already downloaded/extracted if testing list is present\n",
    "\n",
    "    CLASSES = os.listdir(dataset_dir/\"audio\")\n",
    "    \n",
    "    for c in CLASSES :\n",
    "        files = os.listdir(dataset_dir/\"audio\"/c)\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                try:\n",
    "                    wave.open(str(dataset_dir)+\"/audio/\"+c+\"/\"+str(file)) \n",
    "                except:\n",
    "                    os.remove(str(dataset_dir)+\"/audio/\"+c+\"/\"+str(file)) \n",
    "                \n",
    "    numOfrec =min([len(os.listdir(dataset_dir/\"audio\"/c)) for c in CLASSES])\n",
    "    num_test = int(numOfrec*0.1)\n",
    "    for c in CLASSES :\n",
    "        files = os.listdir(dataset_dir/\"audio\"/c)\n",
    "        for f in files[numOfrec:] :\n",
    "            os.remove(dataset_dir/\"audio\"/c/f)\n",
    "    os.open(dataset_dir/'testing_list.txt', os.O_CREAT)\n",
    "    os.open(dataset_dir/'validation_list.txt', os.O_CREAT)\n",
    "    \n",
    "    for c in CLASSES :\n",
    "        i = 0        \n",
    "        for rec in os.listdir(dataset_dir/'audio'/c):\n",
    "            if rec.endswith('.wav') :\n",
    "                if i < num_test :\n",
    "                    with open(dataset_dir/'testing_list.txt', 'a') as f:\n",
    "                        f.write(c + '/' + rec +'\\n')\n",
    "                elif i < num_test*2:\n",
    "                    with open(dataset_dir/'validation_list.txt', 'a') as f:\n",
    "                        f.write(c + '/' + rec +'\\n')\n",
    "                i=i+1\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw spoken digits data from Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9654 training samples and 1071 testing samples\n"
     ]
    }
   ],
   "source": [
    "# Classes to handle, ordered by label\n",
    "with (dataset_dir/'testing_list.txt').open() as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "CLASSES = os.listdir(dataset_dir/\"audio\")\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "audiopath = dataset_dir/'audio'\n",
    "for recording in audiopath.glob(f'**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES: # Ignore unused classes\n",
    "        continue\n",
    "    \n",
    "    label = CLASSES.index(recording.parent.name) # Assign class number\n",
    "    with wave.open(str(recording)) as f: # Read wave file\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy() # As 16-bit signed integer\n",
    "\n",
    "    data = data.astype(np.float32) # Convert to 32-bit floating-point\n",
    "    data.resize((10000, 2)) # Resize to 2s (10kHz) with zero-padding, 1 channel\n",
    "    if str(recording.relative_to(audiopath)).replace('\\\\','/') in testing_list: # Assign to test set if file in test list\n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "    else:\n",
    "        x_train.append(data)\n",
    "        y_train.append(label)\n",
    "\n",
    "print(f'Loaded {len(x_train)} training samples and {len(x_test)} testing samples')\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for inference with fixed-point Q7.9 samples by scaling input data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_POINT = 9\n",
    "x_train /= 2**FIXED_POINT\n",
    "x_test  /= 2**FIXED_POINT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset (250 random vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build model M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 998, 8)            488       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 99, 8)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 97, 8)             200       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 24, 8)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 22, 16)            400       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 5, 16)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 3, 32)             1568      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 3, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 1, 32)            0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,755\n",
      "Trainable params: 2,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(10000, 2)))\n",
    "model.add(Conv1D(filters=8, kernel_size=30, activation='relu',strides=10))\n",
    "model.add(MaxPool1D(pool_size=10))\n",
    "model.add(Conv1D(filters=8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=1))\n",
    "model.add(AvgPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 2s 20ms/step - loss: 0.8072 - categorical_accuracy: 0.6192 - val_loss: 0.9520 - val_categorical_accuracy: 0.5462\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 2s 19ms/step - loss: 0.8193 - categorical_accuracy: 0.6041 - val_loss: 0.9010 - val_categorical_accuracy: 0.5696\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 2s 21ms/step - loss: 0.8061 - categorical_accuracy: 0.6223 - val_loss: 0.9060 - val_categorical_accuracy: 0.5808\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 2s 20ms/step - loss: 0.8016 - categorical_accuracy: 0.6191 - val_loss: 0.9738 - val_categorical_accuracy: 0.5612\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 0.8035 - categorical_accuracy: 0.6260 - val_loss: 0.9485 - val_categorical_accuracy: 0.5668\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 0.8041 - categorical_accuracy: 0.6184 - val_loss: 0.9033 - val_categorical_accuracy: 0.5910\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 0.7931 - categorical_accuracy: 0.6249 - val_loss: 0.9387 - val_categorical_accuracy: 0.5630\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 0.8018 - categorical_accuracy: 0.6210 - val_loss: 0.9322 - val_categorical_accuracy: 0.5705\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 0.8028 - categorical_accuracy: 0.6237 - val_loss: 0.9540 - val_categorical_accuracy: 0.5826\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 0.7970 - categorical_accuracy: 0.6232 - val_loss: 0.9352 - val_categorical_accuracy: 0.5798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b38c079630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.9352 - categorical_accuracy: 0.5798 - 133ms/epoch - 4ms/step\n",
      "34/34 [==============================] - 0s 4ms/step\n",
      "tf.Tensor(\n",
      "[[220  48  89]\n",
      " [ 73 223  61]\n",
      " [142  37 178]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.0142 - categorical_accuracy: 0.5560 - 54ms/epoch - 7ms/step\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "tf.Tensor(\n",
      "[[60 12 15]\n",
      " [18 47 16]\n",
      " [39 11 32]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
      "  Downloading https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 4.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\yimen\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages (from kerascnn2c==1.0.0) (1.22.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yimen\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages (from kerascnn2c==1.0.0) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yimen\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->kerascnn2c==1.0.0) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "import kerascnn2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_1                          | conv1d                          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_1                          | conv1d                           | max_pooling1d                   \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d                           | max_pooling1d                    | conv1d_1                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d                    | conv1d_1                         | max_pooling1d_1                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_1                         | max_pooling1d_1                  | conv1d_2                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_1                  | conv1d_2                         | max_pooling1d_2                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_2                         | max_pooling1d_2                  | conv1d_3                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_2                  | conv1d_3                         | max_pooling1d_3                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_3                         | max_pooling1d_3                  | average_pooling1d               \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_3                  | average_pooling1d                | flatten                         \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "average_pooling1d                | flatten                          | dense                           \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten                          | dense                            |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "After optimization:\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_1                          | conv1d                          \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_1                          | conv1d                           | max_pooling1d                   \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d                           | max_pooling1d                    | conv1d_1                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d                    | conv1d_1                         | max_pooling1d_1                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_1                         | max_pooling1d_1                  | conv1d_2                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_1                  | conv1d_2                         | max_pooling1d_2                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_2                         | max_pooling1d_2                  | conv1d_3                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_2                  | conv1d_3                         | max_pooling1d_3                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_3                         | max_pooling1d_3                  | average_pooling1d               \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_3                  | average_pooling1d                | flatten                         \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "average_pooling1d                | flatten                          | dense                           \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten                          | dense                            |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('gsc_output_fixed'),\n",
    "                           fixed_point=FIXED_POINT, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(model)\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gsc_output_fixed/model.c: In function 'void cnn(const number_t (*)[10000], number_t*)':\n",
      "gsc_output_fixed/model.c:147:18: warning: left operand of comma operator has no effect [-Wunused-value]\n",
      "     activations1.average_pooling1d_output,\n",
      "     ~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!g++ -Wall -Wextra -pedantic -Ofast -o gsc_fixed -Igsc_output_fixed/ gsc_output_fixed/model.c main.cpp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.556\n"
     ]
    }
   ],
   "source": [
    "!\"./gsc_fixed\" x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
